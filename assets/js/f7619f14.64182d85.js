"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[691],{7290:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>d,contentTitle:()=>a,default:()=>c,frontMatter:()=>o,metadata:()=>s,toc:()=>u});var i=t(4848),r=t(8453);const o={sidebar_position:2},a="Run",s={id:"concepts/run",title:"Run",description:"A model run includes tracking the inputs, outputs, and latency of executing a trained machine learning model with specific data to generate predictions.",source:"@site/docs/concepts/run.md",sourceDirName:"concepts",slug:"/concepts/run",permalink:"/docs/concepts/run",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Concepts",permalink:"/docs/category/concepts"},next:{title:"Model",permalink:"/docs/concepts/model"}},d={},u=[{value:"Why trace model run inputs and outputs?",id:"why-trace-model-run-inputs-and-outputs",level:2},{value:"Tracing a model run",id:"tracing-a-model-run",level:2},{value:"Putting it all together",id:"putting-it-all-together",level:3},{value:"Evaluate model run performance",id:"evaluate-model-run-performance",level:2}];function l(n){const e={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.h1,{id:"run",children:"Run"}),"\n",(0,i.jsx)(e.p,{children:"A model run includes tracking the inputs, outputs, and latency of executing a trained machine learning model with specific data to generate predictions."}),"\n",(0,i.jsx)(e.h2,{id:"why-trace-model-run-inputs-and-outputs",children:"Why trace model run inputs and outputs?"}),"\n",(0,i.jsx)(e.p,{children:"Tracing every run input and output is crucial throughout the model lifecycle, from experimentation to production, for several reasons:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Debugging and Error Analysis"}),": Identifies where a model fails or produces unexpected results."]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Performance monitoring"}),": Detects performance degradation, anomalies, or drift by analyzing real-time input and output data"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Optimizing Model Performance"}),": Identifies patterns and trends for further optimizations"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Handling Non-Deterministic Models"}),": Understands and quantifies variability in models that produce different outputs for the same input."]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"tracing-a-model-run",children:"Tracing a model run"}),"\n",(0,i.jsx)(e.p,{children:"BigHummingbird makes it simple to trace a model run input and output values."}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",metastring:'title="model.py"',children:'from bighummingbird import BigHummingbird\nbhb = BigHummingbird("Concept Project", API_KEY)\n\n# Add the trace decorator\n@bhb.trace\ndef model(input_a, input_b):\n  # Your model here\n  # GPT-4 text generation\n  # summarization\n  # translation\n  # sentiment analysis\n  return input_a + input_b\n\nmodel(1, 2)\n'})}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"python model.py\n"})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"View runs and models on a dashboard"}),(0,i.jsx)(e.br,{}),"\n",(0,i.jsx)(e.img,{alt:"run_table",src:t(6865).A+"",width:"1699",height:"462"}),"\n",(0,i.jsx)(e.img,{alt:"model_detail_v1",src:t(2372).A+"",width:"1088",height:"372"})]}),"\n",(0,i.jsxs)(e.p,{children:["This will automatically track your model function signature, outputs, and the model definition. Any changes to these attributes will automatically trigger BigHummingbird to increment your model version. Read ",(0,i.jsx)(e.a,{href:"/docs/concepts/model",children:"Model"})," for more information"]}),"\n",(0,i.jsx)(e.h3,{id:"putting-it-all-together",children:"Putting it all together"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",metastring:'title="model.py"',children:'from bighummingbird import BigHummingbird\nfrom bighummingbird.judge import Judge\n\nbhb = BigHummingbird("Quick Start", API_KEY)\n\ndef scoring_rubric(outputs):\n    # This is important. All necessary imports must be done here.\n    import random\n    return random.randint(1, 10)\n\ndef passing_criteria(score):\n    return score > 5\n\njudge = Judge(\n    "random-judge",\n    "This judge will return a random score between 1 to 10",\n    scoring_rubric,\n    passing_criteria,\n)\njudge_tag = bhb.add_judge(judge)\n\n@bhb.assess(judge_tag)\ndef model(input_a, input_b):\n  # Your model here\n  # GPT-4 text generation\n  # summarization\n  # translation\n  # sentiment analysis\n  return input_a + input_b\n'})}),"\n",(0,i.jsx)(e.h2,{id:"evaluate-model-run-performance",children:"Evaluate model run performance"})]})}function c(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(l,{...n})}):l(n)}},2372:(n,e,t)=>{t.d(e,{A:()=>i});const i=t.p+"assets/images/model_detail_v1-0311113f12a77b96250af893e2c896f3.png"},6865:(n,e,t)=>{t.d(e,{A:()=>i});const i=t.p+"assets/images/run_table-3cf816043c4c1a4b90d71e3a50f89464.png"},8453:(n,e,t)=>{t.d(e,{R:()=>a,x:()=>s});var i=t(6540);const r={},o=i.createContext(r);function a(n){const e=i.useContext(o);return i.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:a(n.components),i.createElement(o.Provider,{value:e},n.children)}}}]);